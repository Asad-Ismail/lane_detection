{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "!  pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import  argparse\n",
    "from utils import dataset\n",
    "from utils import display_sample,show_predictions,create_mask\n",
    "from Models import unetModel\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "from losses import custom_sparse_weighted_crossentropy\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-campbell",
   "metadata": {},
   "source": [
    "## Build and evaluate base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=3\n",
    "EPOCHS = 100\n",
    "ClASSES=5 # Backgroud plus four lanes\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"images_path\"\n",
    "labels=\"labels_path\"\n",
    "lane_data=dataset(data,labels)\n",
    "datasets=lane_data.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(datasets[\"train\"].take(1).as_numpy_iterator())\n",
    "sample_image,sample_label=data[0][0],data[0][1]\n",
    "display_sample([sample_image,sample_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=unetModel()\n",
    "unet=model.get_unet()\n",
    "unet.trainable=True\n",
    "unet.load_weights(\"weights/best_unet_lane_20k_default_ce.h5\")\n",
    "loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "unet.compile(optimizer=Adam(learning_rate=lr), loss =loss,metrics=['accuracy'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_steps=lane_data.val_size//BATCH_SIZE\n",
    "train_steps=lane_data.train_size//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, baseline_model_accuracy = unet.evaluate(datasets[\"val\"],steps=val_steps, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(unet, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getsize(keras_file )*1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-basics",
   "metadata": {},
   "source": [
    "## Apply Pruning on base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-difficulty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = BATCH_SIZE\n",
    "epochs = 1\n",
    "\n",
    "num_images = lane_data.val_size\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "def apply_pruning_to_upsample(layer):\n",
    "    \n",
    "  if isinstance(layer, tf.keras.Model):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer,**pruning_params)\n",
    "\n",
    "  if isinstance(layer, tf.keras.layers.Conv2DTranspose) or isinstance(layer, tf.keras.layers.Conv2D):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer,**pruning_params)\n",
    "\n",
    "  if isinstance(layer, tf.keras.Sequential):\n",
    "        #print(\"Entered Sequential\")\n",
    "        all_layers=[]\n",
    "        for l in layer.layers:\n",
    "            if isinstance(l, tf.keras.layers.Conv2DTranspose) or isinstance(l, tf.keras.layers.Conv2D):\n",
    "                all_layers.append(tfmot.sparsity.keras.prune_low_magnitude(l,**pruning_params))\n",
    "            else:\n",
    "                all_layers.append(l)\n",
    "        return tf.keras.Sequential(all_layers)\n",
    "  return layer\n",
    "\n",
    "model_for_pruning = tf.keras.models.clone_model(unet,clone_function=apply_pruning_to_upsample)\n",
    "\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the sparsity is applied to the sequential layer\n",
    "layers= model_for_pruning.get_layer(\"model\")\n",
    "for layer in layers.layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper import PruneLowMagnitude\n",
    "to_be_pruned=0\n",
    "names=[]\n",
    "for layer in model_for_pruning.layers:\n",
    "    if (isinstance(layer,PruneLowMagnitude)):\n",
    "        to_be_pruned+=1\n",
    "        names.append(layer.name)\n",
    "print(f\"Total layers to be pruned: {to_be_pruned}\")\n",
    "print(f\"Pruned Layers: {names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs\"\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(datasets[\"train\"],batch_size=batch_size,epochs=, steps_per_epoch=train_steps,validation_steps=val_steps,validation_data=datasets['val'],callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_file(model):\n",
    "  _, keras_file = tempfile.mkstemp('.h5') \n",
    "  model.save(keras_file, include_optimizer=False)\n",
    "  return keras_file\n",
    "\n",
    "def get_gzipped_model_size(model):\n",
    "  # It returns the size of the gzipped model in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  keras_file = save_model_file(model)\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(keras_file)\n",
    "  return os.path.getsize(zipped_file)*1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the spatsity is removed from sequential layers\n",
    "#layers= model_for_export.get_layer(\"sequential_5\")\n",
    "#for layer in layers.layers:\n",
    "#    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"Size of gzipped pruned model without stripping: %.2f MB\" % (get_gzipped_model_size(model_for_pruning)))\n",
    "print(\"Size of gzipped pruned model with stripping: %.2f MB\" % (get_gzipped_model_size(model_for_export)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "striped_model_file = 'pruned_upsample.h5'\n",
    "model_for_export.save(striped_model_file, include_optimizer=False)\n",
    "#model_for_export.save(\"pruned.h5\",include_optimizer=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "striped_loaded_model=tf.keras.models.load_model(striped_model_file)\n",
    "#striped_loaded_model=tf.keras.models.load_model(\"pruned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "striped_loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in striped_loaded_model.get_layer(\"sequential_4\").layers:\n",
    "#    print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-princeton",
   "metadata": {},
   "source": [
    "## Apply Clustering to the Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 16,\n",
    "  'cluster_centroids_init': CentroidInitialization.DENSITY_BASED\n",
    "}\n",
    "\n",
    "def apply_clustering_to_upsample(layer):\n",
    "    \n",
    "  if isinstance(layer, tf.keras.layers.Conv2DTranspose) or isinstance(layer, tf.keras.layers.Conv2D):\n",
    "      return tfmot.clustering.keras.cluster_weights(layer,**clustering_params)\n",
    "\n",
    "  if isinstance(layer, tf.keras.Sequential):\n",
    "        #print(\"Entered Sequential\")\n",
    "        all_layers=[]\n",
    "        for l in layer.layers:\n",
    "            if isinstance(l, tf.keras.layers.Conv2DTranspose) or isinstance(l, tf.keras.layers.Conv2D):\n",
    "                all_layers.append(tfmot.clustering.keras.cluster_weights(l,**clustering_params))\n",
    "            else:\n",
    "                all_layers.append(l)\n",
    "        return tf.keras.Sequential(all_layers)\n",
    "  return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_model = tf.keras.models.clone_model(striped_loaded_model,clone_function=apply_clustering_to_upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),metrics=['accuracy'])\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_model.fit(datasets[\"train\"],batch_size=batch_size,epochs=40, steps_per_epoch=train_steps,validation_steps=val_steps,validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tfmot.clustering.keras.cluster_scope():\n",
    "     final_model= tf.keras.models.load_model(\"/tmp/tmprd22o3o8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "final_model = tfmot.clustering.keras.strip_clustering(final_model)\n",
    "#i=0\n",
    "with tfmot.clustering.keras.cluster_scope():\n",
    "    def strip_clustering(layer):\n",
    "        if isinstance(layer, tf.keras.Sequential):    \n",
    "            print(\"Striped Clustering Sequential\")\n",
    "            #i+1\n",
    "            return tfmot.clustering.keras.strip_clustering(layer)\n",
    "        else:\n",
    "            return layer\n",
    "final_model_2 = tf.keras.models.clone_model(final_model,clone_function=strip_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_2.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "_, cluster_model_accuracy = final_model_2.evaluate(datasets[\"val\"],steps=val_steps, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:',  cluster_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model_2.summary())\n",
    "for layer in final_model_2.get_layer(\"sequential_19\").layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of gzipped Original Model: %.2f MB\" % (get_gzipped_model_size(unet)))\n",
    "print(\"Size of gzipped pruned model with stripping: %.2f MB\" % (get_gzipped_model_size(model_for_export)))\n",
    "print(\"Size of gzipped clustered model with stripping: %.2f Megabytes\" % (get_gzipped_model_size(final_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving clustered model to: ', clustered_keras_file)\n",
    "tf.keras.models.save_model(final_model_2, clustered_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "striped_clustered_model=tf.keras.models.load_model(clustered_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "striped_clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tfmot.clustering.keras.cluster_scope():\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(final_model_2)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_quant_model = converter.convert()\n",
    "\n",
    "    _, quantized_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "    with open(quantized_and_clustered_tflite_file, 'wb') as f:\n",
    "      f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-subscription",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
