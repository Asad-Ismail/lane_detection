{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "!  pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complimentary-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import  argparse\n",
    "from utils import dataset\n",
    "from utils import display_sample,show_predictions,create_mask\n",
    "from Models import unetModel\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "from losses import custom_sparse_weighted_crossentropy\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-campbell",
   "metadata": {},
   "source": [
    "## Build and evaluate base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=3\n",
    "EPOCHS = 100\n",
    "ClASSES=5 # Backgroud plus four lanes\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"/media/asad/8800F79D00F79104/lanes_data/20k_images/\"\n",
    "labels=\"/media/asad/8800F79D00F79104/lanes_data/20k_labels/\"\n",
    "lane_data=dataset(data,labels)\n",
    "datasets=lane_data.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(datasets[\"train\"].take(1).as_numpy_iterator())\n",
    "sample_image,sample_label=data[0][0],data[0][1]\n",
    "display_sample([sample_image,sample_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=unetModel()\n",
    "unet=model.get_unet()\n",
    "unet.trainable=True\n",
    "unet.load_weights(\"/media/asad/8800F79D00F79104/best_unet_lane_20k_default_ce.h5\")\n",
    "loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "unet.compile(optimizer=Adam(learning_rate=lr), loss =loss,metrics=['accuracy'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_steps=lane_data.val_size//BATCH_SIZE\n",
    "train_steps=lane_data.train_size//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, baseline_model_accuracy = unet.evaluate(datasets[\"val\"],steps=val_steps, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(unet, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getsize(\"/tmp/tmp6hxc01bn.h5\")*1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-basics",
   "metadata": {},
   "source": [
    "## Apply Pruning on base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-difficulty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = BATCH_SIZE\n",
    "epochs = 1\n",
    "\n",
    "num_images = lane_data.val_size\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "def apply_pruning_to_upsample(layer):\n",
    "  if isinstance(layer, tf.keras.layers.Conv2DTranspose) or isinstance(layer, tf.keras.layers.Conv2D):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer,**pruning_params)\n",
    "\n",
    "  if isinstance(layer, tf.keras.Sequential):\n",
    "        #print(\"Entered Sequential\")\n",
    "        all_layers=[]\n",
    "        for l in layer.layers:\n",
    "            if isinstance(l, tf.keras.layers.Conv2DTranspose) or isinstance(l, tf.keras.layers.Conv2D):\n",
    "                all_layers.append(tfmot.sparsity.keras.prune_low_magnitude(l,**pruning_params))\n",
    "            else:\n",
    "                all_layers.append(l)\n",
    "        return tf.keras.Sequential(all_layers)\n",
    "  return layer\n",
    "\n",
    "model_for_pruning = tf.keras.models.clone_model(unet,clone_function=apply_pruning_to_upsample)\n",
    "\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the sparsity is applied to the sequential layer\n",
    "layers= model_for_pruning.get_layer(\"sequential_5\")\n",
    "for layer in layers.layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper import PruneLowMagnitude\n",
    "to_be_pruned=0\n",
    "names=[]\n",
    "for layer in model_for_pruning.layers:\n",
    "    if (isinstance(layer,PruneLowMagnitude)):\n",
    "        to_be_pruned+=1\n",
    "        names.append(layer.name)\n",
    "print(f\"Total layers to be pruned: {to_be_pruned}\")\n",
    "print(f\"Pruned Layers: {names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(datasets[\"train\"],batch_size=batch_size,epochs=epochs, steps_per_epoch=train_steps,validation_steps=val_steps,validation_data=datasets['val'],callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_file(model):\n",
    "  _, keras_file = tempfile.mkstemp('.h5') \n",
    "  model.save(keras_file, include_optimizer=False)\n",
    "  return keras_file\n",
    "\n",
    "def get_gzipped_model_size(model):\n",
    "  # It returns the size of the gzipped model in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  keras_file = save_model_file(model)\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(keras_file)\n",
    "  return os.path.getsize(zipped_file)*1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, keras_model_file = tempfile.mkstemp('.h5')\n",
    "\n",
    "# Checkpoint: saving the optimizer is necessary (include_optimizer=True is the default).\n",
    "model_for_pruning.save(keras_model_file, include_optimizer=True)\n",
    "print(keras_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tfmot.sparsity.keras.prune_scope():\n",
    "    loaded_model = tf.keras.models.load_model(keras_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper import PruneLowMagnitude\n",
    "type(loaded_model.layers[-1]).__name__\n",
    "with tfmot.sparsity.keras.prune_scope():\n",
    "    print(isinstance(loaded_model.layers[-1],PruneLowMagnitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the spatsity is removed from sequential layers\n",
    "layers= model_for_export.get_layer(\"sequential_5\")\n",
    "for layer in layers.layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"Size of gzipped pruned model without stripping: %.2f MB\" % (get_gzipped_model_size(model_for_pruning)))\n",
    "print(\"Size of gzipped pruned model with stripping: %.2f MB\" % (get_gzipped_model_size(model_for_export)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, striped_model_file = tempfile.mkstemp('.h5')\n",
    "#model_for_export.save(striped_model_file, include_optimizer=False)\n",
    "model_for_export.save(\"pruned.h5\",include_optimizer=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "legal-composer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#striped_loaded_model=tf.keras.models.load_model(striped_model_file)\n",
    "striped_loaded_model=tf.keras.models.load_model(\"pruned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "striped_loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in striped_loaded_model.get_layer(\"sequential_4\").layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(striped_loaded_model)\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "#_, quantized_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "#with open(quantized_tflite_file, 'wb') as f:\n",
    "#  f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-princeton",
   "metadata": {},
   "source": [
    "## Apply Clustering to the Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 3,\n",
    "  'cluster_centroids_init': CentroidInitialization.DENSITY_BASED\n",
    "}\n",
    "\n",
    "def apply_clustering_to_upsample(layer):    \n",
    "  if isinstance(layer, tf.keras.layers.Conv2DTranspose) or isinstance(layer, tf.keras.layers.Conv2D):\n",
    "      return tfmot.clustering.keras.cluster_weights(layer,**clustering_params)\n",
    "\n",
    "  if isinstance(layer, tf.keras.Sequential):\n",
    "        #print(\"Entered Sequential\")\n",
    "        all_layers=[]\n",
    "        for l in layer.layers:\n",
    "            if isinstance(l, tf.keras.layers.Conv2DTranspose) or isinstance(l, tf.keras.layers.Conv2D):\n",
    "                all_layers.append(tfmot.clustering.keras.cluster_weights(l,**clustering_params))\n",
    "            else:\n",
    "                all_layers.append(l)\n",
    "        return tf.keras.Sequential(all_layers)\n",
    "  return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_model = tf.keras.models.clone_model(striped_loaded_model,clone_function=apply_clustering_to_upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),metrics=['accuracy'])\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_model.fit(datasets[\"train\"],batch_size=batch_size,epochs=epochs, steps_per_epoch=train_steps,validation_steps=val_steps,validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "actual-statement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "with tfmot.clustering.keras.cluster_scope():\n",
    "     final_model= tf.keras.models.load_model(\"/tmp/tmprd22o3o8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "after-treasury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Striped Clustering Sequential\n",
      "Striped Clustering Sequential\n",
      "Striped Clustering Sequential\n",
      "Striped Clustering Sequential\n"
     ]
    }
   ],
   "source": [
    "final_model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "final_model = tfmot.clustering.keras.strip_clustering(final_model)\n",
    "#i=0\n",
    "with tfmot.clustering.keras.cluster_scope():\n",
    "    def strip_clustering(layer):\n",
    "        if isinstance(layer, tf.keras.Sequential):    \n",
    "            print(\"Striped Clustering Sequential\")\n",
    "            i+1\n",
    "            return tfmot.clustering.keras.strip_clustering(layer)\n",
    "        else:\n",
    "            return layer\n",
    "final_model_2 = tf.keras.models.clone_model(final_model,clone_function=strip_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "inside-native",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 384, 640, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   [(None, 192, 320, 96 1841984     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 24, 40, 512)  1476608     model[3][4]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 24, 40, 1088) 0           sequential_8[0][0]               \n",
      "                                                                 model[3][3]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 48, 80, 256)  2507776     concatenate[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48, 80, 448)  0           sequential_9[0][0]               \n",
      "                                                                 model[3][2]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 96, 160, 128) 516608      concatenate_1[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 160, 272) 0           sequential_10[0][0]              \n",
      "                                                                 model[3][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 192, 320, 64) 156928      concatenate_2[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 192, 320, 160 0           sequential_11[0][0]              \n",
      "                                                                 model[3][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 384, 640, 5)  7205        concatenate_3[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,507,109\n",
      "Trainable params: 6,474,277\n",
      "Non-trainable params: 32,832\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2DTranspose object at 0x7f0c8a0a4630>\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f0c8a0a4e48>\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f0c8a030080>\n"
     ]
    }
   ],
   "source": [
    "print(final_model_2.summary())\n",
    "for layer in final_model_2.get_layer(\"sequential_11\").layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "english-upper",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_gzipped_model_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-27b23862c06f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of gzipped Original Model: %.2f MB\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_gzipped_model_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of gzipped pruned model with stripping: %.2f MB\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_gzipped_model_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_for_export\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of gzipped clustered model with stripping: %.2f Megabytes\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_gzipped_model_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_gzipped_model_size' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped Original Model: %.2f MB\" % (get_gzipped_model_size(unet)))\n",
    "print(\"Size of gzipped pruned model with stripping: %.2f MB\" % (get_gzipped_model_size(model_for_export)))\n",
    "print(\"Size of gzipped clustered model with stripping: %.2f Megabytes\" % (get_gzipped_model_size(final_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "becoming-induction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving clustered model to:  /tmp/tmp8xl60oyj.h5\n"
     ]
    }
   ],
   "source": [
    "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving clustered model to: ', clustered_keras_file)\n",
    "tf.keras.models.save_model(final_model_2, clustered_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "pediatric-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "striped_clustered_model=tf.keras.models.load_model(\"/tmp/tmp8xl60oyj.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "severe-subject",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 384, 640, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   [(None, 192, 320, 96 1841984     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 24, 40, 512)  1476608     model[1][4]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 24, 40, 1088) 0           sequential_8[0][0]               \n",
      "                                                                 model[1][3]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 48, 80, 256)  2507776     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48, 80, 448)  0           sequential_9[0][0]               \n",
      "                                                                 model[1][2]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 96, 160, 128) 516608      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 160, 272) 0           sequential_10[0][0]              \n",
      "                                                                 model[1][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 192, 320, 64) 156928      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 192, 320, 160 0           sequential_11[0][0]              \n",
      "                                                                 model[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 384, 640, 5)  7205        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,507,109\n",
      "Trainable params: 6,474,277\n",
      "Non-trainable params: 32,832\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "striped_clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "editorial-hartford",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "See console for info.\n2021-02-28 23:44:48.164514: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.\n2021-02-28 23:44:48.164543: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.\n2021-02-28 23:44:48.247987: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2\n2021-02-28 23:44:48.269554: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3499910000 Hz\n2021-02-28 23:44:48.269777: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560201e089e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2021-02-28 23:44:48.269795: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2021-02-28 23:44:48.270481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n2021-02-28 23:44:48.274241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.274471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\ncoreClock: 1.607GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n2021-02-28 23:44:48.274617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n2021-02-28 23:44:48.275729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n2021-02-28 23:44:48.276799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n2021-02-28 23:44:48.277019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n2021-02-28 23:44:48.278155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n2021-02-28 23:44:48.278711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n2021-02-28 23:44:48.281107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n2021-02-28 23:44:48.281231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.281564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.281770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n2021-02-28 23:44:48.281807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n2021-02-28 23:44:48.328734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-02-28 23:44:48.328757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n2021-02-28 23:44:48.328763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n2021-02-28 23:44:48.328887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.329153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.329378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.329592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 174 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2021-02-28 23:44:48.330901: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5602015ed350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n2021-02-28 23:44:48.330919: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n2021-02-28 23:44:49.252601: F ./tensorflow/core/kernels/conv_2d_gpu.h:970] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, kNumThreads, kTileSize, kTileSize, conjugate>, total_tiles_count, kNumThreads, 0, d.stream(), input, input_dims, output) status: Internal: out of memory\nFatal Python error: Aborted\n\nCurrent thread 0x00007fb5521dd740 (most recent call first):\n  File \"/home/asad/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56 in execute\n  File \"/home/asad/anaconda/envs/tf2/lib/python3.6/site-packages/absl/app.py\", line 251 in _run_main\n  File \"/home/asad/anaconda/envs/tf2/lib/python3.6/site-packages/absl/app.py\", line 303 in run\n  File \"/home/asad/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40 in run\n  File \"/home/asad/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93 in main\n  File \"/home/asad/anaconda/envs/tf2/bin/toco_from_protos\", line 11 in <module>\nAborted (core dumped)\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3d7a84755289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtflite_quant_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantized_and_clustered_tflite_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkstemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         **converter_kwargs)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_calibration_quantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    497\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConverterError\u001b[0m: See console for info.\n2021-02-28 23:44:48.164514: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.\n2021-02-28 23:44:48.164543: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.\n2021-02-28 23:44:48.247987: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2\n2021-02-28 23:44:48.269554: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3499910000 Hz\n2021-02-28 23:44:48.269777: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560201e089e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2021-02-28 23:44:48.269795: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2021-02-28 23:44:48.270481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n2021-02-28 23:44:48.274241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.274471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\ncoreClock: 1.607GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n2021-02-28 23:44:48.274617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n2021-02-28 23:44:48.275729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n2021-02-28 23:44:48.276799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n2021-02-28 23:44:48.277019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n2021-02-28 23:44:48.278155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n2021-02-28 23:44:48.278711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n2021-02-28 23:44:48.281107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n2021-02-28 23:44:48.281231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.281564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.281770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n2021-02-28 23:44:48.281807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n2021-02-28 23:44:48.328734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-02-28 23:44:48.328757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n2021-02-28 23:44:48.328763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n2021-02-28 23:44:48.328887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.329153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.329378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-02-28 23:44:48.329592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 174 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2021-02-28 23:44:48.330901: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5602015ed350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n2021-02-28 23:44:48.330919: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n2021-02-28 23:44:49.252601: F ./tensorflow/core/kernels/conv_2d_gpu.h:970] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, kNumThreads, kTileSize, kTileSize, conjugate>, total_tiles_count, kNumThreads, 0, d.stream(), input, input_dims, output) status: Internal: out of memory\nFatal Python error: Aborted\n\nCurrent thread 0x00007fb5521dd740 (most recent call first):\n  File \"/home/asad/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56 in execute\n  File \"/home/asad/anaconda/envs/tf2/lib/python3.6/site-packages/absl/app.py\", line 251 in _run_main\n  File \"/home/asad/anaconda/envs/tf2/lib/python3.6/site-packages/absl/app.py\", line 303 in run\n  File \"/home/asad/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40 in run\n  File \"/home/asad/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93 in main\n  File \"/home/asad/anaconda/envs/tf2/bin/toco_from_protos\", line 11 in <module>\nAborted (core dumped)\n\n\n"
     ]
    }
   ],
   "source": [
    "with tfmot.clustering.keras.cluster_scope():\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_quant_model = converter.convert()\n",
    "\n",
    "    _, quantized_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "    with open(quantized_and_clustered_tflite_file, 'wb') as f:\n",
    "      f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-subscription",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
